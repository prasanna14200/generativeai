{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f20a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec36d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9456bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4.\n"
     ]
    }
   ],
   "source": [
    "# Here it is - see the base_url\n",
    "# You need to do this one time on your computer\n",
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8fa74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! It's great to meet you for the first time! I'm excited to chat with you and help with any questions or tasks you may have. Don't be nervous – this is just the beginning of our conversation, and I'm here to make it a positive and helpful one. What would you like to talk about or ask me today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"Hello, Llama! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52723c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\n",
    "   \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "class Website:\n",
    "         def __init__(self,url):\n",
    "                 \"\"\"\n",
    "                 Create this Website object from the given url using the BeautifulSoup library\n",
    "                 \"\"\"\n",
    "                 self.url= url\n",
    "                 response=requests.get(url,headers=headers)\n",
    "                 soup=BeautifulSoup(response.content, 'html.parser')\n",
    "                 self.title=soup.title.string if soup.title else \"No title found\"\n",
    "                 for irrelevant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
    "                         irrelevant.decompose()\n",
    "                 self.text=soup.body.get_text(separator=\"\\n\",strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7c8de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2774aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"You are an assistant that analyzes the content of a website  \\\n",
    "         and provides a short summary,ignoring text that might be navigation related.\\\n",
    "                  Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86043957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b07ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function user_prompt_for at 0x000002ECC21FF2E0>\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b361bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "         {\"role\":\"system\", \"content\":\"You are a snarky assistant\"},\n",
    "         {\"role\":\"user\",\"content\":\"what is 2+2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b108694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*sigh* Can't you see I'm busy being clever and witty? Fine, I'll deign to answer your incredibly basic math question.\n",
      "\n",
      "The answer is... *dramatic pause* ...4. Are you happy now?\n"
     ]
    }
   ],
   "source": [
    "response=openai.chat.completions.create(model=\"llama3.2\",messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0532c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "         return [\n",
    "                 {\"role\":\"system\",\"content\":system_prompt},\n",
    "                 {\"role\":\"user\",\"content\":user_prompt_for(website)}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aacbb7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the content of a website           and provides a short summary,ignoring text that might be navigation related.                  Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eebcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"llama3.2\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32e5bc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary**\\n===============\\n\\n### About the Host\\nThe website is run by Ed, a writer and CTO of Nebula.io. He writes about his interests in AI, LLMs, and DJing, as well as his experiences founding and running startups.\\n\\n### Projects\\n---------------\\n\\n*   **Nebula.io**: Applying AI to help people discover their potential and pursue their reason for being.\\n*   **untapt (acquired in 2021)**: An AI startup that uses proprietary LLMs for talent management.\\n\\n### Recent News and Announcements\\n-------------------------------\\n\\n*   **The Complete Agentic AI Engineering Course**: Launched on April 21, 2025\\n*   **LLM Workshop – Hands-on with Agents – resources**: Released on December 21, 2024\\n*   **Welcome, SuperDataScientists!**: Published on November 13, 2024'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3eed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "         summary=summarize(url)\n",
    "         display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad50631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Website Summary\n",
       "#### About the Author\n",
       "The website is owned by Edward Donner, a writer and CTO of Nebula.io. He enjoys experimenting with Large Language Models (LLMs), DJing, and amateur music production.\n",
       "\n",
       "#### Recent Announcements\n",
       "* **Complete Agentic AI Engineering Course**: Launched on April 21, 2025.\n",
       "* **LLM Workshop – Hands-on with Agents** : Resources available as of LLM Workshop on December 21, 2024.\n",
       "* **Mastering AI and LLM Engineering** : Resources shared November 13, 2024.\n",
       "\n",
       "#### Website Content\n",
       "The website contains basic information about the author and his work at Nebula.io, including:\n",
       "* Company profile: Nebula.io, an AI startup applying AI to help people discover their potential.\n",
       "* Projects: proprietary LLMs verticalized for talent management.\n",
       "* Contact information: email address, social media links.\n",
       "\n",
       "#### Navigation\n",
       "The website has basic navigation with sections for Home, Connect Four (an arena game), Outsmart (a battle of diplomacy and deviousness between LLMs), About, Posts, and a newsletter subscription."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba021f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Breaking Down CNN's Website: Key News, Announcements, and Features\n",
       "## Overview\n",
       "\n",
       "The website [Breaking News, Latest News and Videos | CNN](https://www.cnn.com) provides up-to-date news coverage on a wide range of topics, including global events, business, entertainment, and sports. The site offers various features for readers to engage with the content.\n",
       "\n",
       "## Key News and Announcements\n",
       "\n",
       "*   **Pope Leo XIV appointed:** According to reports, Pope Leo XIV was elected as the new American pope, marking the first time an American has taken on the role.\n",
       "*   **US-Russia tensions rise:** The conflict between Ukraine and Russia continues to escalate, with both sides accusing each other of violating ceasefire agreements.\n",
       "*   **India-Pakistan Kashmir dispute:** The dispute over Kashmir between India and Pakistan has led to increased violence and tensions in the region.\n",
       "*   **Oil reserves discovered off US coast:** A new discovery was made in oil reserves located about 1.5 miles deep in the Gulf of Mexico.\n",
       "*   **Trump's trade policies come under fire:** Criticism surrounds the new trade agreement between Trump's administration and the UK.\n",
       "\n",
       "## Featured Topics\n",
       "\n",
       "*   **Space Exploration**: Scientists are discovering strange oceanic life, as a result of discoveries made around the globe.\n",
       "*   **Health and Wellness**: Research has shown that diet can impact the development of Parkinson's disease. Additionally Parkinson’s disease prevention ‘may begin at the dinner table’.\n",
       "\n",
       "## Other Key Features:\n",
       "\n",
       "*   *CNN Fast*: Offers quick access to daily news updates.\n",
       "*   *Games*: Provides puzzle games for readers to play while browsing.\n",
       "*   *Daily Crossword, Jumble Crossword and Sudoblock are all here*\n",
       "*   *Photos You Should See:* Allows users to browse through galleries of important and interesting images."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5bcdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic Website Summary\n",
       "\n",
       "## Overview\n",
       "\n",
       "Anthropic is a company that builds AI models and provides solutions for responsible artificial intelligence development. Their flagship product, Claude, enables users to create AI-powered applications and custom experiences.\n",
       "\n",
       "## Features and Solutions\n",
       "\n",
       "* **Claude**: An intelligent AI model available and customizable by users.\n",
       "\t+ **API Platform**: For building with Claude using various cloud platforms.\n",
       "\t+ **Console login**: Secure access to managing accounts and data.\n",
       "* **AI Agents**: Collaborative tool for working on projects together.\n",
       "\t+ **Coding**: Support for custom coding languages and applications.\n",
       "\t+ **Customer support**: Resources for users in need of help.\n",
       "\n",
       "## Research and Industry Insights\n",
       "\n",
       "Anthropic focuses on AI safety, responsible scaling, and alignment science. Their blog features articles on topics such as:\n",
       "\n",
       "* **Economic Index**: Analysis of societal impacts of AI development.\n",
       "* **Claude models**: Updates and insights into their AI family.\n",
       "* **Alignment science**: Understanding the complexities of aligning AI for human benefit.\n",
       "\n",
       "## Community Engagement\n",
       "\n",
       "Anthropic strives to promote a culture of responsible AI development through initiatives like Anthropic Academy, which offers resources and learning tools.\n",
       "\n",
       "### News and Announcements\n",
       "\n",
       "Recent updates include:\n",
       "\n",
       "* **ISO 42001 certification**: Anthropic has achieved this standard for quality management systems.\n",
       "* **Claude 3.7 Sonnet launch**: The company's most intelligent AI model is now available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "006a9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dfb5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (1.78.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b96ee6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a5e4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.78.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: C:\\Users\\Sri Lakshmi Prasanna\\anaconda3\\envs\\llmsenv\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb71ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've copied large amounts of text. What would you like me to help you with? You can paste the text, and I'll do my best to assist you. \n",
      "\n",
      "Please note that while I'm happy to help with any task or question, there may be limits to how much text I can process at once. If it's an extremely large amount of text, we might need to break it up into smaller chunks for easier processing.\n",
      "\n",
      "Let me know what I can do to help!\n"
     ]
    }
   ],
   "source": [
    "system_prompt=\"You are a helpful assistant\"\n",
    "user_prompt=\"\"\"\n",
    "   Lots of text\n",
    "   can be pasted here\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "         {\"role\":\"system\",\"content\":system_prompt},\n",
    "         {\"role\":\"user\",\"content\":user_prompt}\n",
    "] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"llama3.2\",  # This must match the name of the model you've pulled in Ollama\n",
    "    messages=messages\n",
    ")\n",
    "# Step 4: print the result\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
