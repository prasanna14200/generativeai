{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751f3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12664382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to the classic math problem is:\n",
      "\n",
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here it is - see the base_url\n",
    "# You need to do this one time on your computer\n",
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f493200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.links = []\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "            self.body = response.content\n",
    "            soup = BeautifulSoup(self.body, 'html.parser')\n",
    "\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"\"\n",
    "\n",
    "            links = [link.get('href') for link in soup.find_all('a')]\n",
    "            self.links = [link for link in links if link]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching or parsing {url}: {e}\")\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106009f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://edwarddonner.com/', 'https://edwarddonner.com/connect-four/', 'https://edwarddonner.com/outsmart/', 'https://edwarddonner.com/about-me-and-about-nebula/', 'https://edwarddonner.com/posts/', 'https://edwarddonner.com/', 'https://news.ycombinator.com', 'https://nebula.io/?utm_source=ed&utm_medium=referral', 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html', 'https://patents.google.com/patent/US20210049536A1/', 'https://www.linkedin.com/in/eddonner/', 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/', 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/', 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/', 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/', 'https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/', 'https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/', 'https://edwarddonner.com/2024/11/13/llm-engineering-resources/', 'https://edwarddonner.com/2024/11/13/llm-engineering-resources/', 'https://edwarddonner.com/', 'https://edwarddonner.com/connect-four/', 'https://edwarddonner.com/outsmart/', 'https://edwarddonner.com/about-me-and-about-nebula/', 'https://edwarddonner.com/posts/', 'mailto:hello@mygroovydomain.com', 'https://www.linkedin.com/in/eddonner/', 'https://twitter.com/edwarddonner', 'https://www.facebook.com/edward.donner.52']\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d29f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt=\"You are provided with a list of links found on a webpage. \\\n",
    "         You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "                  such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt+=\"You should respond in JSON as this example:\"\n",
    "link_system_prompt+=\"\"\"\n",
    "{ \n",
    "      \"links\":[\n",
    "      {\"type\":\"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "      {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "\n",
    "      ]\n",
    "\n",
    "\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20431a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage.          You are able to decide which of the links would be most relevant to include in a brochure about the company,                   such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as this example:\n",
      "{ \n",
      "      \"links\":[\n",
      "      {\"type\":\"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "      {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "\n",
      "      ]\n",
      "\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e07f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "         user_prompt=f\"Here is the list of links on the website of {website.url} -\"\n",
    "         user_prompt+=\"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "                  Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "         user_prompt+=\"Links (some might be relative links):\\n\"\n",
    "         user_prompt+=\"\\n\".join(website.links)\n",
    "         return user_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6415d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com -please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format.                   Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/\n",
      "https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f763f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "         website=Website(url)\n",
    "         response=openai.chat.completions.create(\n",
    "                 model=MODEL,\n",
    "                 messages=[\n",
    "                         {\"role\":\"system\",\"content\":link_system_prompt},\n",
    "                         {\"role\":\"user\",\"content\":get_links_user_prompt(website)}\n",
    "\n",
    "                 ],\n",
    "                 response_format={\"type\":\"json_object\"}\n",
    "         )\n",
    "         result=response.choices[0].message.content\n",
    "         return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9db4155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nvidia/parakeet-tdt-0.6b-v2',\n",
       " '/nari-labs/Dia-1.6B',\n",
       " '/ACE-Step/ACE-Step-v1-3.5B',\n",
       " '/Lightricks/LTX-Video',\n",
       " '/lodestones/Chroma',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/smolagents/computer-agent',\n",
       " '/spaces/ByteDance/DreamO',\n",
       " '/spaces/NihalGazi/FLUX-Pro-Unlimited',\n",
       " '/spaces/ACE-Step/ACE-Step',\n",
       " '/spaces',\n",
       " '/datasets/openbmb/Ultra-FineWeb',\n",
       " '/datasets/DMindAI/DMind_Benchmark',\n",
       " '/datasets/nvidia/OpenCodeReasoning',\n",
       " '/datasets/PrimeIntellect/INTELLECT-2-RL-Dataset',\n",
       " '/datasets/nvidia/OpenMathReasoning',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://ui.endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f6d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "         result=\"Landing page:\\n\"\n",
    "         result+=Website(url).get_contents()\n",
    "         links=get_links(url)\n",
    "         print(\"Found links:\",links)\n",
    "         for link in links[\"links\"]:\n",
    "                 result+=f\"\\n\\n{link['type']}\\n\"\n",
    "                 result+=Website(link[\"url\"]).get_contents()\n",
    "         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b8038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'About/Hugging Face', 'url': 'https://huggingface.co/'}, {'type': 'Careers/Hugging Face', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'Blog/Hugging Face', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub/Hugging Face', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter/Hugging Face', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn/Hugging Face', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Brand Page/Hugging Face', 'url': 'https://huggingface.co/brand'}, {'type': 'GitHub Repository/Parakeet-TDT-0.6B', 'url': 'https://github.com/nvidia/parakeet-tdt-0.6b-v2'}]}\n",
      "Error fetching or parsing https://github.com/nvidia/parakeet-tdt-0.6b-v2: 404 Client Error: Not Found for url: https://github.com/nvidia/parakeet-tdt-0.6b-v2\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "162k\n",
      "•\n",
      "858\n",
      "nari-labs/Dia-1.6B\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "172k\n",
      "•\n",
      "2.17k\n",
      "ACE-Step/ACE-Step-v1-3.5B\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "422\n",
      "Lightricks/LTX-Video\n",
      "Updated\n",
      "about 20 hours ago\n",
      "•\n",
      "288k\n",
      "•\n",
      "1.48k\n",
      "lodestones/Chroma\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "533\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "6.57k\n",
      "6.57k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "610\n",
      "610\n",
      "Computer Agent\n",
      "🖥\n",
      "Interact with an AI agent to perform web tasks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "322\n",
      "322\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "Running\n",
      "355\n",
      "355\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "350\n",
      "350\n",
      "ACE Step\n",
      "😻\n",
      "A Step Towards Music Generation Foundation Model\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "3.5k\n",
      "•\n",
      "55\n",
      "DMindAI/DMind_Benchmark\n",
      "Updated\n",
      "about 20 hours ago\n",
      "•\n",
      "2.16k\n",
      "•\n",
      "73\n",
      "nvidia/OpenCodeReasoning\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "15.4k\n",
      "•\n",
      "407\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "338\n",
      "•\n",
      "29\n",
      "nvidia/OpenMathReasoning\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "36.5k\n",
      "•\n",
      "225\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "757 models\n",
      "•\n",
      "3.27k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.12k models\n",
      "•\n",
      "5.95k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.16k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "991 models\n",
      "•\n",
      "13.2k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "221 models\n",
      "•\n",
      "2.54k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "374 models\n",
      "•\n",
      "12.3k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "144,363\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "28,991\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,265\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,598\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,684\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "13,744\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,596\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "18,659\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,411\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,114\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,117\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,720\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "About/Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "162k\n",
      "•\n",
      "858\n",
      "nari-labs/Dia-1.6B\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "172k\n",
      "•\n",
      "2.17k\n",
      "ACE-Step/ACE-Step-v1-3.5B\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "422\n",
      "Lightricks/LTX-Video\n",
      "Updated\n",
      "about 20 hours ago\n",
      "•\n",
      "288k\n",
      "•\n",
      "1.48k\n",
      "lodestones/Chroma\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "533\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "6.57k\n",
      "6.57k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "610\n",
      "610\n",
      "Computer Agent\n",
      "🖥\n",
      "Interact with an AI agent to perform web tasks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "322\n",
      "322\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "Running\n",
      "355\n",
      "355\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "350\n",
      "350\n",
      "ACE Step\n",
      "😻\n",
      "A Step Towards Music Generation Foundation Model\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "3.5k\n",
      "•\n",
      "55\n",
      "DMindAI/DMind_Benchmark\n",
      "Updated\n",
      "about 21 hours ago\n",
      "•\n",
      "2.16k\n",
      "•\n",
      "73\n",
      "nvidia/OpenCodeReasoning\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "15.4k\n",
      "•\n",
      "407\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "338\n",
      "•\n",
      "29\n",
      "nvidia/OpenMathReasoning\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "36.5k\n",
      "•\n",
      "225\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "757 models\n",
      "•\n",
      "3.27k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.12k models\n",
      "•\n",
      "5.95k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.16k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "991 models\n",
      "•\n",
      "13.2k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "221 models\n",
      "•\n",
      "2.54k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "374 models\n",
      "•\n",
      "12.3k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "144,363\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "28,991\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,265\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,598\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,684\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "13,744\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,596\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "18,659\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,411\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,114\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,117\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,720\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "Careers/Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Blog/Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "Help this newbie\n",
      "Beginners\n",
      "6\n",
      "31\n",
      "May 15, 2025\n",
      "“Use this model”->Ollama: can't pull model with Q4\n",
      "🤗Hub\n",
      "4\n",
      "27\n",
      "May 15, 2025\n",
      "Inference API Rate Limits\n",
      "Inference Endpoints on the Hub\n",
      "1\n",
      "8\n",
      "May 16, 2025\n",
      "Problem with API\n",
      "Beginners\n",
      "1\n",
      "18\n",
      "May 15, 2025\n",
      "How to freeze layers while fine-tuning?\n",
      "🤗Transformers\n",
      "1\n",
      "13\n",
      "May 15, 2025\n",
      "FineTune LLM on a behavior strategy\n",
      "Beginners\n",
      "2\n",
      "13\n",
      "May 15, 2025\n",
      "Can't load exist dataset for evaluation\n",
      "🤗Datasets\n",
      "4\n",
      "675\n",
      "May 15, 2025\n",
      "Ask AI for help with a query and fix with AI don't work\n",
      "Beginners\n",
      "3\n",
      "9\n",
      "May 15, 2025\n",
      "Persistent 404 Not Found Errors with Public Inference API\n",
      "Inference Endpoints on the Hub\n",
      "8\n",
      "195\n",
      "May 15, 2025\n",
      "504 timeout error\n",
      "Beginners\n",
      "1\n",
      "14\n",
      "May 15, 2025\n",
      "Persistent DNS Resolution Errors\n",
      "Spaces\n",
      "19\n",
      "349\n",
      "May 10, 2025\n",
      "Lfs Storage cap\n",
      "Spaces\n",
      "1\n",
      "11\n",
      "May 15, 2025\n",
      "Can I write to the file system?\n",
      "Spaces\n",
      "1\n",
      "11\n",
      "May 15, 2025\n",
      "ZeroGPU space : No CUDA GPUs are available\n",
      "Spaces\n",
      "3\n",
      "53\n",
      "May 14, 2025\n",
      "Fine Tuning DeepSeek v3?\n",
      "Beginners\n",
      "1\n",
      "14\n",
      "May 15, 2025\n",
      "How to download a model and run it with Ollama locally?\n",
      "Beginners\n",
      "17\n",
      "113296\n",
      "May 15, 2025\n",
      "Hugging Face Payment Error 402 & You've Exceeded Monthly Quota\n",
      "Languages at Hugging Face\n",
      "20\n",
      "733\n",
      "May 15, 2025\n",
      "Bert integrated web app with Markdown as input passage\n",
      "Beginners\n",
      "2\n",
      "9\n",
      "May 15, 2025\n",
      "Why using Ai can resolve a lot despair\n",
      "Beginners\n",
      "1\n",
      "15\n",
      "May 15, 2025\n",
      "Can I create a dataset for fine-tuning the llama model like in the main text?\n",
      "Beginners\n",
      "2\n",
      "10\n",
      "May 15, 2025\n",
      "Trainer default distributed training behaviour\n",
      "🤗Transformers\n",
      "2\n",
      "7\n",
      "May 15, 2025\n",
      "Issues about deepspeed&Qlora&SFT: RuntimeError: grad can be implicitly created only for scalar outputs\n",
      "Beginners\n",
      "4\n",
      "13\n",
      "May 14, 2025\n",
      "Program not working on GPU but works on CPU\n",
      "Intermediate\n",
      "15\n",
      "29\n",
      "May 15, 2025\n",
      "But is there even a single model working here?!\n",
      "Models\n",
      "4\n",
      "280\n",
      "May 10, 2025\n",
      "Load a COCO format database from disk for DETR\n",
      "🤗Datasets\n",
      "4\n",
      "24\n",
      "May 14, 2025\n",
      "Handling Extreme Class Imbalance for Multi-Class Classification\n",
      "Intermediate\n",
      "1\n",
      "11\n",
      "May 14, 2025\n",
      "Fail to claim authorship of the paper\n",
      "Beginners\n",
      "10\n",
      "100\n",
      "May 15, 2025\n",
      "Potential issue with spaces analytics not working\n",
      "Spaces\n",
      "5\n",
      "37\n",
      "May 14, 2025\n",
      "Dose Prediction model with 3D input images\n",
      "Beginners\n",
      "0\n",
      "5\n",
      "May 14, 2025\n",
      "Multiple Spaces have stopped working\n",
      "Beginners\n",
      "5\n",
      "125\n",
      "May 13, 2025\n",
      "next page →\n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "GitHub/Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face · GitHub\n",
      "Webpage Contents:\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "huggingface\n",
      "Product\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "Discussions\n",
      "Collaborate outside of code\n",
      "Code Search\n",
      "Find more, search less\n",
      "Explore\n",
      "Why GitHub\n",
      "All features\n",
      "Documentation\n",
      "GitHub Skills\n",
      "Blog\n",
      "Solutions\n",
      "By company size\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "By use case\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "By industry\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "Topics\n",
      "AI\n",
      "DevOps\n",
      "Security\n",
      "Software Development\n",
      "View all\n",
      "Explore\n",
      "Learning Pathways\n",
      "Events & Webinars\n",
      "Ebooks & Whitepapers\n",
      "Customer Stories\n",
      "Partners\n",
      "Executive Insights\n",
      "Open Source\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "The ReadME Project\n",
      "GitHub community articles\n",
      "Repositories\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "Available add-ons\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more quickly\n",
      "Cancel\n",
      "Create saved search\n",
      "Sign in\n",
      "Sign up\n",
      "Appearance settings\n",
      "Reseting focus\n",
      "You signed in with another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You signed out in another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You switched accounts on another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "Dismiss alert\n",
      "Hugging Face\n",
      "The AI community building the future.\n",
      "Verified\n",
      "We've verified that the organization\n",
      "huggingface\n",
      "controls the domain:\n",
      "huggingface.co\n",
      "Learn more about verified organizations\n",
      "48.9k\n",
      "followers\n",
      "NYC + Paris\n",
      "https://huggingface.co/\n",
      "X\n",
      "@huggingface\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "0\n",
      "More\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "Pinned\n",
      "Loading\n",
      "transformers\n",
      "transformers\n",
      "Public\n",
      "🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "Python\n",
      "144k\n",
      "29k\n",
      "diffusers\n",
      "diffusers\n",
      "Public\n",
      "🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n",
      "Python\n",
      "29k\n",
      "6k\n",
      "datasets\n",
      "datasets\n",
      "Public\n",
      "🤗 The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools\n",
      "Python\n",
      "20.1k\n",
      "2.8k\n",
      "peft\n",
      "peft\n",
      "Public\n",
      "🤗 PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.\n",
      "Python\n",
      "18.4k\n",
      "1.9k\n",
      "accelerate\n",
      "accelerate\n",
      "Public\n",
      "🚀 A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support\n",
      "Python\n",
      "8.7k\n",
      "1.1k\n",
      "optimum\n",
      "optimum\n",
      "Public\n",
      "🚀 Accelerate inference and training of 🤗 Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\n",
      "Python\n",
      "2.9k\n",
      "537\n",
      "Repositories\n",
      "Loading\n",
      "Type\n",
      "Select type\n",
      "Forks\n",
      "Archived\n",
      "Mirrors\n",
      "Templates\n",
      "Language\n",
      "Select language\n",
      "All\n",
      "C\n",
      "C#\n",
      "C++\n",
      "Cuda\n",
      "Dockerfile\n",
      "Go\n",
      "Handlebars\n",
      "HTML\n",
      "Java\n",
      "JavaScript\n",
      "Jupyter Notebook\n",
      "Kotlin\n",
      "Lua\n",
      "MDX\n",
      "Mustache\n",
      "Nix\n",
      "Python\n",
      "Rust\n",
      "Shell\n",
      "Smarty\n",
      "Svelte\n",
      "Swift\n",
      "TypeScript\n",
      "Sort\n",
      "Select order\n",
      "Last updated\n",
      "Name\n",
      "Stars\n",
      "Showing 10 of 313 repositories\n",
      "trl\n",
      "Public\n",
      "Train transformer language models with reinforcement learning.\n",
      "huggingface/trl’s past year of commit activity\n",
      "Python\n",
      "13,746\n",
      "Apache-2.0\n",
      "1,881\n",
      "386\n",
      "70\n",
      "Updated\n",
      "May 16, 2025\n",
      "xet-core\n",
      "Public\n",
      "xet client tech, used in huggingface_hub\n",
      "huggingface/xet-core’s past year of commit activity\n",
      "Rust\n",
      "95\n",
      "Apache-2.0\n",
      "12\n",
      "8\n",
      "11\n",
      "Updated\n",
      "May 16, 2025\n",
      "hf-workflows\n",
      "Public\n",
      "huggingface/hf-workflows’s past year of commit activity\n",
      "5\n",
      "8\n",
      "0\n",
      "1\n",
      "Updated\n",
      "May 15, 2025\n",
      "transformers\n",
      "Public\n",
      "🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "huggingface/transformers’s past year of commit activity\n",
      "Python\n",
      "144,363\n",
      "Apache-2.0\n",
      "28,950\n",
      "1,046\n",
      "(2 issues need help)\n",
      "748\n",
      "Updated\n",
      "May 15, 2025\n",
      "chat-ui\n",
      "Public\n",
      "Open source codebase powering the HuggingChat app\n",
      "huggingface/chat-ui’s past year of commit activity\n",
      "TypeScript\n",
      "8,707\n",
      "Apache-2.0\n",
      "1,308\n",
      "311\n",
      "(1 issue needs help)\n",
      "21\n",
      "Updated\n",
      "May 15, 2025\n",
      "pytorch-image-models\n",
      "Public\n",
      "The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more\n",
      "huggingface/pytorch-image-models’s past year of commit activity\n",
      "Python\n",
      "34,137\n",
      "Apache-2.0\n",
      "4,915\n",
      "51\n",
      "(4 issues need help)\n",
      "23\n",
      "Updated\n",
      "May 15, 2025\n",
      "optimum-habana\n",
      "Public\n",
      "Easy and lightning fast training of 🤗 Transformers on Habana Gaudi processor (HPU)\n",
      "huggingface/optimum-habana’s past year of commit activity\n",
      "Python\n",
      "186\n",
      "Apache-2.0\n",
      "257\n",
      "18\n",
      "(1 issue needs help)\n",
      "31\n",
      "Updated\n",
      "May 15, 2025\n",
      "hfendpoints\n",
      "Public\n",
      "SDK for creating Hugging Face Inference Endpoints deployments\n",
      "huggingface/hfendpoints’s past year of commit activity\n",
      "Rust\n",
      "6\n",
      "1\n",
      "0\n",
      "1\n",
      "Updated\n",
      "May 15, 2025\n",
      "text-generation-inference\n",
      "Public\n",
      "Large Language Model Text Generation Inference\n",
      "huggingface/text-generation-inference’s past year of commit activity\n",
      "Python\n",
      "10,117\n",
      "Apache-2.0\n",
      "1,194\n",
      "248\n",
      "28\n",
      "Updated\n",
      "May 15, 2025\n",
      "candle\n",
      "Public\n",
      "Minimalist ML framework for Rust\n",
      "huggingface/candle’s past year of commit activity\n",
      "Rust\n",
      "17,196\n",
      "Apache-2.0\n",
      "1,095\n",
      "414\n",
      "(5 issues need help)\n",
      "114\n",
      "Updated\n",
      "May 15, 2025\n",
      "View all repositories\n",
      "People\n",
      "View all\n",
      "Top languages\n",
      "Python\n",
      "Jupyter Notebook\n",
      "Rust\n",
      "TypeScript\n",
      "JavaScript\n",
      "Most used topics\n",
      "Loading…\n",
      "Footer\n",
      "© 2025 GitHub, Inc.\n",
      "Footer navigation\n",
      "Terms\n",
      "Privacy\n",
      "Security\n",
      "Status\n",
      "Docs\n",
      "Contact\n",
      "Manage cookies\n",
      "Do not share my personal information\n",
      "You can’t perform that action at this time.\n",
      "\n",
      "\n",
      "\n",
      "Twitter/Hugging Face\n",
      "Webpage Title:\n",
      "No title found\n",
      "Webpage Contents:\n",
      "JavaScript is not available.\n",
      "We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n",
      "Help Center\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Imprint\n",
      "Ads info\n",
      "© 2025 X Corp.\n",
      "Something went wrong, but don’t fret — let’s give it another shot.\n",
      "Try again\n",
      "Some privacy related extensions may cause issues on x.com. Please disable them and try again.\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn/Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Articles\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 535 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "We’re on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Tech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\n",
      "Jeff Boudier\n",
      "Product + Growth at Hugging Face\n",
      "Terrence Rohan\n",
      "Seed Investor\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "63,522 followers\n",
      "10h\n",
      "Report this post\n",
      "Learn about the trio powering Model Context Protocol (MCP)👇\n",
      "\n",
      "🧠 Host = the LLM app (Claude Desktop, IDEs, even your Gradio Chatbots)\n",
      "🧰 Server = the tool with specific capability (APIs or Gradio apps)\n",
      "🔗 Client = maintains 1:1 connection with the Server from inside the Host\n",
      "\n",
      "Guides for further reading and building MCP-powered apps 👇\n",
      "🚀 Create end-to-end applications with Gradio chat interface as the Host and Gradio apps as Servers:\n",
      "https://lnkd.in/gTpTJMCy\n",
      "🔥 Create MCP Servers with Gradio for your IDEs, Claude Desktop, or custom Hosts:\n",
      "https://lnkd.in/g2yg-NGX\n",
      "32\n",
      "1 Comment\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Lysandre Debut\n",
      "COSO - Chief Open Source Officer at Hugging Face\n",
      "11h\n",
      "Report this post\n",
      "The Transformers library is undergoing it's largest pivot to date 🙌\n",
      "\n",
      "It now cements its role as the central model definition, irrespective of the backend and runner. One ground truth to bring more reliability across the ecosystem.\n",
      "\n",
      "This comes into play as Transformers becomes a backend of:\n",
      "\n",
      "- most popular inference engines like vLLM, SGLang, TGI, TensorRT, ...\n",
      "- training frameworks like Axolotl, Unsloth, DeepSpeed, FSDP, PyTorch-Lightning, ...\n",
      "- and adjacent modeling libraries like\n",
      "llama.cpp\n",
      ", MLX, ONNX, ...\n",
      "\n",
      "Transformers is the pivot across frameworks: if a model is integrated, then you're certain it is handled by the rest of the ecosystem. \n",
      "\n",
      "In a field where ML releases are more and more frequent, keeping track of integrations in all downstream libraries can become a headache.\n",
      "\n",
      "By having Transformers as a backend, you get immediate access to all 300+ supported architectures, and you're ensured immediate access to upcoming model releases.\n",
      "\n",
      "This often means day-0 access, but also community-fixes, and a shared baseline for evaluation.\n",
      "\n",
      "This means that we'll strive to continuously improve Transformers so that:\n",
      "\n",
      "-  Integrations are simpler & faster\n",
      "- Models continue being adaptable, customizable\n",
      "- Model definitions remain simple, easily augmented by downstream libraries.\n",
      "\n",
      "Read more about it in the following blog post:\n",
      "https://lnkd.in/eQjmcWxF\n",
      "599\n",
      "9 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Ben Burtenshaw\n",
      "Machine Learning Advocacy @ 🤗 Hugging Face\n",
      "11h\n",
      "Report this post\n",
      "We're thrilled to announce the launch of our comprehensive Model Context Protocol (MCP) Course! This free program is designed to take learners from foundational understanding to practical application of MCP in AI.\n",
      "\n",
      "Join the course on the hub:\n",
      "https://lnkd.in/eTuSr-Uh\n",
      "In this course, you will:\n",
      "📖 Study Model Context Protocol in theory, design, and practice.\n",
      "🧑💻 Learn to use established MCP SDKs and frameworks.\n",
      "💾 Share your projects and explore applications created by the community.\n",
      "🏆 Participate in challenges and evaluate your MCP implementations.\n",
      "🎓 Earn a certificate of completion.\n",
      "\n",
      "At the end, you'll understand how MCP works and how to build your own AI applications that leverage external data and tools using the latest MCP standards.\n",
      "1,469\n",
      "47 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Marc Sun\n",
      "ML Engineer @HuggingFace 🤗 | CentraleSupélec | Columbia\n",
      "13h\n",
      "Report this post\n",
      "🚀 Accelerate v1.7.0 is here!\n",
      "\n",
      "Highlights of this release: \n",
      "- 🧩 Regional compilation by\n",
      "Ilyas Moutawwakil\n",
      "- 🧠 Layerwise casting hook by\n",
      "Sayak Paul\n",
      ", a widely used feature in diffusers repository\n",
      "- ⚡QLoRA support for FSDPv2 by\n",
      "Wing Lian\n",
      "Release notes:\n",
      "https://lnkd.in/eTxrarYa\n",
      "76\n",
      "4 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Pollen Robotics\n",
      "10,518 followers\n",
      "18h\n",
      "Report this post\n",
      "3 robots heading to\n",
      "Humanoids Summit\n",
      "London 2025!\n",
      "\n",
      "If you're around, come say hi. We'll be showing:\n",
      " 🤖 Reachy 2, now able to react emotionally and understand multiple languages. We'll also show you what Reachy is able to do through teleoperation.\n",
      " 🦆 Mini Duck,\n",
      "Antoine Pirrone\n",
      "'s project, doing what it does best: wandering freely and charming everyone.\n",
      " 🦾 And for the first time ever in public: David A6DoF, a joint project by Antoine and\n",
      "Augustin CRAMPETTE\n",
      "We’re also proud to see\n",
      "Santiago Ismael Pavon\n",
      "and\n",
      "Remi Cadene\n",
      "from\n",
      "Hugging Face\n",
      "speaking on stage, diving into some of the key topics around Embodied AI.\n",
      "\n",
      " 📍See you there?\n",
      "58\n",
      "4 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Shaun Smith\n",
      "llmindset.co.uk\n",
      "1d\n",
      "Report this post\n",
      "A couple of weeks ago\n",
      "Julien Chaumond\n",
      "shared Tiny Agent - 50 lines of code that showed how powerful combining LLMs and Tools together is (with MCP providing the \"glue\"). \n",
      "\n",
      "We've made a small, but very useful update:- you can now connect to Remote MCP Servers (including\n",
      "Gradio\n",
      "endpoints) straight from the command line - making it even easier to add Agent Capabilities to that while loop. Enjoy!\n",
      "105\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Freddy Boulton\n",
      "Software Engineer @ 🤗\n",
      "2d\n",
      "Report this post\n",
      "Just launched: 8x faster Whisper transcription endpoints on\n",
      "Hugging Face\n",
      "⚡️\n",
      "\n",
      "Powered by vLLM and optimized for NVIDIA GPUs. Same accuracy, way better performance!\n",
      "…more\n",
      "214\n",
      "8 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Ben Burtenshaw\n",
      "Machine Learning Advocacy @ 🤗 Hugging Face\n",
      "2d\n",
      "Report this post\n",
      "AgentCPM-GUI from Open BMB looks like an interesting GUI agent model to watch. It's a smaller model at 7 billion parameters but beats models like Gemini-2.0 on mobile UI control benchmarks. \n",
      "\n",
      "model:\n",
      "https://lnkd.in/eFbgCHzg\n",
      "dataset:\n",
      "https://lnkd.in/e5xjFZ2M\n",
      "repo:\n",
      "https://lnkd.in/eGuQz2KP\n",
      "44\n",
      "1 Comment\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at 🤗\n",
      "2d\n",
      "Report this post\n",
      "What’s new in reasoning datasets?\n",
      "\n",
      "Over the past few months, we’ve seen the release of many high-quality datasets on\n",
      "Hugging Face\n",
      "that aim to stretch the reasoning capabilities of language models — from symbolic mathematics to multimodal understanding and academic intuition.\n",
      "\n",
      "Here’s a short roundup of *some* of these datasets \n",
      "\n",
      "📘 DeepMath-103K\n",
      "\n",
      "A meticulously curated dataset of over 100K advanced math problems, each with verified answers, difficulty ratings, and multiple reasoning paths.\n",
      "\n",
      "It supports both supervised and reinforcement learning (RL), and has already enabled new SOTA results (85.5% on MATH 500 using a 7B model).\n",
      "\n",
      "Great for training models that reason through complex, multi-step calculations — and for evaluating them fairly, thanks to careful decontamination.\n",
      "\n",
      "Dataset:\n",
      "https://lnkd.in/evJD9xvN\n",
      "---\n",
      "\n",
      "🖼️ MMPR-v1.2\n",
      "\n",
      "This massive 3M+ example dataset focuses on multimodal reasoning preferences.\n",
      "\n",
      "Built to train InternVL2 with Mixed Preference Optimization (MPO), it significantly improves performance on MathVista and other VQA benchmarks — and reduces hallucinations along the way.\n",
      "\n",
      "What stands out is the balance of scale, diversity, and targeted data curation for visual reasoning tasks.\n",
      "\n",
      "Dataset:\n",
      "https://lnkd.in/eHu_jamK\n",
      "---\n",
      "\n",
      "🔬 Academic Reasoning and Intuition Chains\n",
      "\n",
      "This dataset builds structured reasoning chains directly from open-access scientific papers — focusing on pre-experimental intuition and conceptual thinking.\n",
      "\n",
      "Each example includes <think> tags, domain labels, and LLM-based verification to ensure the chains reflect genuine reasoning (not result summaries).\n",
      "\n",
      "Ideal for training models that “think like a researcher,” especially in STEM domains.\n",
      "\n",
      "Dataset:\n",
      "https://lnkd.in/emUz-BuD\n",
      "---\n",
      "\n",
      "🧪 MMK12\n",
      "\n",
      "A high-quality multimodal reasoning dataset built entirely from real-world images and questions — spanning maths, physics, chemistry, and biology.\n",
      "\n",
      "Unlike synthetic benchmarks, the QA pairs here are verified by humans and sourced from real contexts.\n",
      "\n",
      "Used to train MM-EUREKA, which ranks just behind GPT-4o and o1 on relevant multimodal science tasks.\n",
      "\n",
      "Dataset:\n",
      "https://lnkd.in/eAEAQsf4\n",
      "---\n",
      "\n",
      "and finally my own modest contribution! \n",
      "\n",
      "📚 Fine Reasoning Questions\n",
      "\n",
      "Most reasoning datasets focus on math, code, or science. This one takes a different approach — generating reasoning questions from web texts in domains like finance, politics, and the environment.\n",
      "\n",
      "It’s a proof-of-concept that shows how using models like Qwen + the Curator  library can be used to generate high-quality, domain-specific questions from raw web data.\n",
      "\n",
      "It’s also tagged by whether the question requires the original context — making it useful for both open- and closed-book tasks.\n",
      "\n",
      "Dataset:\n",
      "https://lnkd.in/enCDrJ_B\n",
      "Excited to see what the next few months brings!\n",
      "148\n",
      "10 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "open-sourceress at 🤗 | Google Developer Expert in Machine Learning, MSc Candidate in Data Science\n",
      "3d\n",
      "Report this post\n",
      "VLMS 2025 UPDATE 🔥\n",
      "\n",
      "We just shipped a blog on everything latest on vision language models, including\n",
      "🤖 GUI agents, agentic VLMs, omni models\n",
      "📑 multimodal RAG\n",
      "⏯️ video LMs\n",
      "🤏🏻 smol models\n",
      "..and more! \n",
      "\n",
      "find it in comments 💬\n",
      "1,122\n",
      "24 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Generative AI\n",
      "Technology, Information and Internet\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Palo Alto, California\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "LlamaIndex\n",
      "Technology, Information and Internet\n",
      "San Francisco, California\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      "© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "العربية (Arabic)\n",
      "বাংলা (Bangla)\n",
      "Čeština (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "Ελληνικά (Greek)\n",
      "English (English)\n",
      "Español (Spanish)\n",
      "فارسی (Persian)\n",
      "Suomi (Finnish)\n",
      "Français (French)\n",
      "हिंदी (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "עברית (Hebrew)\n",
      "日本語 (Japanese)\n",
      "한국어 (Korean)\n",
      "मराठी (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "ਪੰਜਾਬੀ (Punjabi)\n",
      "Polski (Polish)\n",
      "Português (Portuguese)\n",
      "Română (Romanian)\n",
      "Русский (Russian)\n",
      "Svenska (Swedish)\n",
      "తెలుగు (Telugu)\n",
      "ภาษาไทย (Thai)\n",
      "Tagalog (Tagalog)\n",
      "Türkçe (Turkish)\n",
      "Українська (Ukrainian)\n",
      "Tiếng Việt (Vietnamese)\n",
      "简体中文 (Chinese (Simplified))\n",
      "正體中文 (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Don’t have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n",
      "\n",
      "Brand Page/Hugging Face\n",
      "Webpage Title:\n",
      "Brand assets - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face · Brand assets\n",
      "HF Logos\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      "HF Colors\n",
      "#FFD21E\n",
      "#FF9D00\n",
      "#6B7280\n",
      "HF Bio\n",
      "Hugging Face is the collaboration platform for the machine learning community.\n",
      "\n",
      "The Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\n",
      "\n",
      "With the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolution.\n",
      "Copy to clipboard\n",
      "HF Universe\n",
      "Find other assets available for use from the Hugging Face brand universe\n",
      "here\n",
      ".\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "GitHub Repository/Parakeet-TDT-0.6B\n",
      "Webpage Title:\n",
      "\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb57c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0769b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "         user_prompt = \"\"\n",
    "         user_prompt+=f\"You are looking at a company called: {company_name}\\n\"\n",
    "         user_prompt+=f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown. \\n\"\n",
    "         user_prompt+=get_all_details(url)\n",
    "         user_prompt=user_prompt[:5_000]\n",
    "         return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013db47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'About page', 'url': 'https://huggingface.co/'}, {'type': 'Company page', 'url': 'https://huggingface.co/'}, {'type': 'Careers/Jobs page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'Blog', 'url': 'https://blog.huggingface.co/'}, {'type': 'Discussions Forum', 'url': 'https://discuss.huggingface.co/'}, {'type': 'Status Page', 'url': 'https://status.huggingface.co/'}, {'type': 'GitHub Repository', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter Handle', 'url': 'https://twitter.com/huggingface'}, {'type': '.LinkedIn Company Profile', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n",
      "Error fetching or parsing https://blog.huggingface.co/: HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002148A753920>: Failed to resolve 'blog.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown. \\nLanding page:\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nnvidia/parakeet-tdt-0.6b-v2\\nUpdated\\nabout 1 hour ago\\n•\\n162k\\n•\\n858\\nnari-labs/Dia-1.6B\\nUpdated\\n2 days ago\\n•\\n172k\\n•\\n2.17k\\nACE-Step/ACE-Step-v1-3.5B\\nUpdated\\n3 days ago\\n•\\n422\\nLightricks/LTX-Video\\nUpdated\\nabout 20 hours ago\\n•\\n288k\\n•\\n1.48k\\nlodestones/Chroma\\nUpdated\\n2 days ago\\n•\\n533\\nBrowse 1M+ models\\nSpaces\\nRunning\\n6.57k\\n6.57k\\nDeepSite\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nCPU Upgrade\\n610\\n610\\nComputer Agent\\n🖥\\nInteract with an AI agent to perform web tasks\\nRunning\\non\\nZero\\n322\\n322\\nDreamO\\n🐨\\nA Unified Framework for Image Customization\\nRunning\\n355\\n355\\nFLUX Pro Unlimited\\n🔥\\nUse the FLUX-Pro model as much as you want.\\nRunning\\non\\nZero\\n350\\n350\\nACE Step\\n😻\\nA Step Towards Music Generation Foundation Model\\nBrowse 400k+ applications\\nDatasets\\nopenbmb/Ultra-FineWeb\\nUpdated\\n7 days ago\\n•\\n3.5k\\n•\\n55\\nDMindAI/DMind_Benchmark\\nUpdated\\nabout 21 hours ago\\n•\\n2.16k\\n•\\n73\\nnvidia/OpenCodeReasoning\\nUpdated\\n11 days ago\\n•\\n15.4k\\n•\\n407\\nPrimeIntellect/INTELLECT-2-RL-Dataset\\nUpdated\\n3 days ago\\n•\\n338\\n•\\n29\\nnvidia/OpenMathReasoning\\nUpdated\\n6 days ago\\n•\\n36.5k\\n•\\n225\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n757 models\\n•\\n3.27k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.12k models\\n•\\n5.95k followers\\nAmazon\\ncompany\\n•\\n20 models\\n•\\n3.16k followers\\nGoogle\\ncompany\\n•\\n991 models\\n•\\n13.2k followers\\nIntel\\ncompany\\n•\\n221 models\\n•\\n2.54k followers\\nMicrosoft\\ncompany\\n•\\n374 models\\n•\\n12.3k followers\\nGrammarly\\nEnterprise\\ncompany\\n•\\n10 models\\n•\\n160 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n21 models\\n•\\n267 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n144,363\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n28,991\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,265\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,598\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,684\\nFast tokenizers optimized for research & production\\nTRL\\n13,744\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,596\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n18,659\\nSmol library to build great agents in Python\\nPEFT\\n18,411\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,114\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,117\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,720\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nAbout page\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nnvidia/parakeet-tdt-0.6b-v2\\nUpdated\\nabout 1 hour ago\\n•\\n162k\\n•\\n858\\nnari-labs/Dia-1.6B\\nUpdated\\n2 days ago\\n•\\n172k\\n•\\n2.17k\\nACE-Step/ACE-Step-v1-3.5B\\nUpdated\\n3 days ago\\n•\\n422\\nLightricks/LTX-Video\\nUpdated\\nabout 20 hours ago\\n•\\n288k\\n•\\n1.48k\\nlodestones/Chroma\\nUpdated\\n2 days ago\\n•\\n533\\nBrowse 1M+ models\\nSpaces\\nRunning\\n6.57k\\n6.57k\\nDeepSite\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nCPU Upgrade\\n610\\n610\\nComputer Agent\\n🖥\\nInteract with an AI agent to perform web tasks\\nRunning\\non\\nZ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa900628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "         response=openai.chat.completions.create(\n",
    "                 model=MODEL,\n",
    "                 messages=[\n",
    "                         {\"role\":\"system\",\"content\":system_prompt},\n",
    "                         {\"role\":\"user\",\"content\":get_brochure_user_prompt(company_name, url)}\n",
    "\n",
    "                 ],\n",
    "         )\n",
    "\n",
    "         result=response.choices[0].message.content\n",
    "         display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6715a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'About Us', 'url': 'https://huggingface.co'}, {'type': 'Company/Enterprise', 'url': 'https://huggingface.co/enterprise'}, {'type': 'Careers/Jobs', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'Blog', 'url': 'https://blog.huggingface.co'}, {'type': 'Discussions', 'url': 'https://discuss.huggingface.co'}, {'type': 'Status/Support', 'url': 'https://status.huggingface.co/'}, {'type': 'GitHub Repository', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'FAQs', 'url': 'https://huggingface.co/docs'}, {'type': 'Models', 'url': 'https://huggingface.co/models'}]}\n",
      "Error fetching or parsing https://blog.huggingface.co: HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002148B015CD0>: Failed to resolve 'blog.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Hugging Face is the premier platform for the machine learning community, empowering individuals and organizations to build, collaborate, and accelerate their AI applications.\n",
       "\n",
       "### Our Mission\n",
       "\n",
       "To create a collaborative environment where researchers, developers, and businesses can come together to push the boundaries of Artificial Intelligence.\n",
       "\n",
       "### Who We Are\n",
       "\n",
       "Hugging Face is driven by our passion for the potential of AI to transform industries and improve lives. Our community-driven platform encourages experimentation, innovation, and collaboration across various modalities, including text, image, video, audio, and 3D.\n",
       "\n",
       "## Our Core Offerings\n",
       "\n",
       "*   **Models**: Browse over 1 million pre-trained models optimized for various applications.\n",
       "*   **Datasets**: Access and share a vast array of datasets to augment your AI projects.\n",
       "*   **Spaces**: Publish and run unlimited public models, datasets, and applications with ease.\n",
       "*   **Compute**: Get access to optimized inference endpoints and GPU deployment capabilities.\n",
       "\n",
       "### Key Features\n",
       "\n",
       "*   **Community Engagement**: Join over 50,000 organizations using our platform, including Meta, Amazon, Google, Intel, Microsoft, Grammarly, and Writer.\n",
       "*   **Accelerate Your ML Journey**: Utilize our compute services to train your models faster with multi-GPU or TPU support.\n",
       "\n",
       "### Transforming Industries\n",
       "\n",
       "Hugging Face is revolutionizing the field of AI and enabling businesses to build, deploy, and maintain their own machine learning models.\n",
       "\n",
       "## Stay Ahead of the Curve\n",
       "\n",
       "Join our growing community today! Sign up for a free account and start exploring our platform:\n",
       "\n",
       "[Sign up now](https://huggingface.co/login)\n",
       "\n",
       "## Career Opportunities\n",
       "\n",
       "Ready to join the Hugging Face team? Explore our current job openings:\n",
       "\n",
       "[ careers ](https://careers.huggingface.co/)\n",
       "\n",
       "## Get in Touch\n",
       "\n",
       "Want to connect with us directly? Follow us on social media or visit our website:\n",
       "\n",
       "[ Website ](https://huggingface.co/)\n",
       "[@ HuggingFace On Twitter](https://twitter.com/HuggingFace)\n",
       "[ LinkedIn Hugging Face ](https://www.linkedin.com/company/hugging-face-ai/)\n",
       "\n",
       "---\n",
       "\n",
       "Stay up to date with our latest publications, research papers, and insights into the world of AI! Follow us:\n",
       "\n",
       "[@ PaperHuggingOn GitHub](https://github.com/HuggingFace?)\n",
       "[@ paper_hugging_on Twitter](/)\n",
       "[ The Official Hugging Face Blog ](https://blog.huggingface.co/)\n",
       "\n",
       "---\n",
       "\n",
       "#"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7247e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "         stream=openai.chat.completions.create(\n",
    "                 model=MODEL,\n",
    "                 messages=[\n",
    "                         {\"role\":\"system\",\"content\":system_prompt},\n",
    "                         {\"role\":\"user\",\"content\":get_brochure_user_prompt(company_name,url)}\n",
    "                 ],\n",
    "                 stream=True\n",
    "                 \n",
    "         )\n",
    "\n",
    "         response= \"\"\n",
    "         display_handle=display(Markdown(\"\"), display_id=True)\n",
    "         for chunk in stream:\n",
    "                  response+=chunk.choices[0].delta.content or ''\n",
    "                  response=response.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "                  update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb93df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'Company Page', 'url': 'https://huggingface.co/'}, {'type': 'About Page', 'url': 'https://huggingface.co/blog'}, {'type': 'Careers Page', 'url': 'https://ai.huggingface.co/ jobs'}, {'type': 'Products', 'url': 'https://huggingface.co/models'}, {'type': 'Documentation', 'url': 'https://huggingface.co/docs'}, {'type': 'Blog', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub Repository', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter Handle', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn Company Page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n",
      "Error fetching or parsing https://ai.huggingface.co/ jobs: HTTPSConnectionPool(host='ai.huggingface.co', port=443): Max retries exceeded with url: /%20jobs (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002148A1ACE60>: Failed to resolve 'ai.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Hugging Face Brochure**\n",
       "=========================\n",
       "\n",
       "**Welcome to Hugging Face**\n",
       "---------------------------\n",
       "\n",
       "We're the AI community building the future. Our platform is where the machine learning community collaborates on models, datasets, and applications.\n",
       "\n",
       "**What We Do**\n",
       "-----------------\n",
       "\n",
       "* **Build, Discover, and Collaborate**: Host and collaborate on unlimited public models, datasets, and applications.\n",
       "* **Accelerate Your ML**: Leverage our Hugging Face Open source stack to move faster with AI.\n",
       "* **Explore All Modalities**: Text, image, video, audio or 3D - we support it all.\n",
       "\n",
       "**Community Highlights**\n",
       "-------------------------\n",
       "\n",
       "*   **1M+ Models**: Browse from a vast library of pre-trained models and create your own.\n",
       "*   **10k+ Datasets**: Access and share datasets for any ML tasks.\n",
       "*   **50,000+ Organizations**: Join the ranks of companies like Meta, Google, Amazon, Intel, and Microsoft using our platform.\n",
       "\n",
       "**Our Mission**\n",
       "----------------\n",
       "\n",
       "We're building the foundation of ML tooling with the community. Our open-source projects include:\n",
       "\n",
       "*   Transformers\n",
       "*   Diffusers\n",
       "*   Safetensors\n",
       "*   Tokenizers\n",
       "*   TRL (Train Transformed Language Models)\n",
       "*   Transformers.js\n",
       "*   Smolagents\n",
       "*   PEFT\n",
       "\n",
       "**Join Us**\n",
       "--------------\n",
       "\n",
       "Sign up to accelerate your ML and contribute to our mission.\n",
       "\n",
       "[Get Started](Link to sign-up)\n",
       "\n",
       "### Culture at Hugging Face\n",
       "------------------------------------\n",
       "\n",
       "We prioritize a collaborative, inclusive culture that empowers everyone to participate.\n",
       "\n",
       "### Opportunities\n",
       "---------------\n",
       "\n",
       "We offer various roles across data science, software engineering, sales, and more. Explore our open positions now [here](link).\n",
       "\n",
       "### Careers\n",
       "---------\n",
       "\n",
       "[Learn More](Link to careers)\n",
       "\n",
       "*   **Jobs**: Stay updated on openings at Hugging Face.\n",
       "*   **Internships**: Apply for internships to get hands-on experience.\n",
       "*   **Events**: Attending Webinars, meetups and conferences\n",
       "\n",
       "### About Us\n",
       "--------------\n",
       "\n",
       "[Read Our Story](link to about us page)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brochure_data=stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7caf40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_brochure(brochure_data):\n",
    "    if brochure_data is None:\n",
    "        brochure_data = {}\n",
    "\n",
    "    if \"Features and Services\" not in brochure_data or brochure_data[\"Features and Services\"] is None:\n",
    "        brochure_data[\"Features and Services\"] = {}\n",
    "\n",
    "    brochure_data[\"Features and Services\"].update({\n",
    "        \"Datasets\": (\n",
    "            \"Access thousands of public datasets for tasks like text classification, translation, \"\n",
    "            \"image generation, audio processing, and more, all integrated with the Hugging Face Hub.\"\n",
    "        ),\n",
    "        \"Spaces\": (\n",
    "            \"Host and demo ML apps using Gradio or Streamlit. Spaces let developers build interactive showcases.\"\n",
    "        ),\n",
    "        \"Transformers\": (\n",
    "            \"Access pre-trained models like BERT, GPT, RoBERTa, and more using Hugging Face Transformers library.\"\n",
    "        ),\n",
    "        \"Inference API\": (\n",
    "            \"Easily deploy any model to production via the Inference API with minimal setup.\"\n",
    "        ),\n",
    "        \"Community\": (\n",
    "            \"Join researchers and developers around the world. Contribute, discuss, and share ideas.\"\n",
    "        )\n",
    "    })\n",
    "    return brochure_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4085cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Features and Services': {'Datasets': 'Access thousands of public datasets for tasks like text classification, translation, image generation, audio processing, and more, all integrated with the Hugging Face Hub.', 'Spaces': 'Host and demo ML apps using Gradio or Streamlit. Spaces let developers build interactive showcases.', 'Transformers': 'Access pre-trained models like BERT, GPT, RoBERTa, and more using Hugging Face Transformers library.', 'Inference API': 'Easily deploy any model to production via the Inference API with minimal setup.', 'Community': 'Join researchers and developers around the world. Contribute, discuss, and share ideas.'}}\n"
     ]
    }
   ],
   "source": [
    "brochure_data = {}\n",
    "brochure_data = enhance_brochure(brochure_data)\n",
    "print(brochure_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e949dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_markdown(brochure_data, filename=\"brochure.md\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        for section, content in brochure_data.items():\n",
    "            file.write(f\"# {section}\\n\\n\")\n",
    "            if isinstance(content, dict):\n",
    "                for sub_section, detail in content.items():\n",
    "                    file.write(f\"## {sub_section}\\n\\n{detail}\\n\\n\")\n",
    "            else:\n",
    "                file.write(f\"{content}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ad050ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(export_to_markdown(brochure_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0281d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: markdown\n",
      "Successfully installed markdown-3.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002613CAB8890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/markdown/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/51/3f/afe76f8e2246ffbc867440cbcf90525264df0e658f8a5ca1f872b3f6192a/markdown-3.8-py3-none-any.whl.metadata\n"
     ]
    }
   ],
   "source": [
    "!pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26665b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "\n",
    "def export_to_html(markdown_file=\"brochure.md\", html_file=\"brochure.html\"):\n",
    "    with open(markdown_file, \"r\", encoding=\"utf-8\") as md_file:\n",
    "        md_text = md_file.read()\n",
    "        html = markdown.markdown(md_text)\n",
    "    with open(html_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee10ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_html()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09fb9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown2\n",
      "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pdfkit\n",
      "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Downloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
      "Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pdfkit, markdown2\n",
      "\n",
      "   ---------------------------------------- 2/2 [markdown2]\n",
      "\n",
      "Successfully installed markdown2-2.5.3 pdfkit-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install markdown2 pdfkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ce3e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wkhtmltopdf\n",
      "  Downloading wkhtmltopdf-0.2.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wkhtmltopdf\n",
      "  Building wheel for wkhtmltopdf (setup.py): started\n",
      "  Building wheel for wkhtmltopdf (setup.py): finished with status 'done'\n",
      "  Created wheel for wkhtmltopdf: filename=wkhtmltopdf-0.2-py3-none-any.whl size=11216 sha256=e396aced6f831aa25e014f448b13f34dcf67b1dc9b59834a0c4ee1d7005da29a\n",
      "  Stored in directory: c:\\users\\sri lakshmi prasanna\\appdata\\local\\pip\\cache\\wheels\\d7\\df\\5a\\6a89a343df16c425adc9591b782d1250ee0a25df08225f81c7\n",
      "Successfully built wkhtmltopdf\n",
      "Installing collected packages: wkhtmltopdf\n",
      "Successfully installed wkhtmltopdf-0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'wkhtmltopdf' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wkhtmltopdf'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install wkhtmltopdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edf4d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown2\n",
    "import pdfkit\n",
    "import os\n",
    "\n",
    "def export_to_pdf(markdown_file=\"brochure.md\", pdf_file=\"brochure.pdf\", wkhtmltopdf_path=None):\n",
    "    if not os.path.exists(markdown_file):\n",
    "        print(f\"Error: Markdown file '{markdown_file}' not found.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with open(markdown_file, \"r\", encoding=\"utf-8\") as md_file:\n",
    "            markdown_content = md_file.read()\n",
    "\n",
    "        html = markdown2.markdown(markdown_content)\n",
    "\n",
    "        # Provide wkhtmltopdf path if passed\n",
    "        if wkhtmltopdf_path:\n",
    "            config = pdfkit.configuration(wkhtmltopdf=wkhtmltopdf_path)\n",
    "            pdfkit.from_string(html, pdf_file, configuration=config)\n",
    "        else:\n",
    "            pdfkit.from_string(html, pdf_file)\n",
    "\n",
    "        if os.path.exists(pdf_file):\n",
    "            print(f\"✅ PDF successfully created: {pdf_file}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Error: PDF file '{pdf_file}' was not created.\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during PDF conversion: {str(e)}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99e85a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkhtmltopdf_path = r\"C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0096ec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF successfully created: brochure.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_to_pdf(\"brochure.md\", \"brochure.pdf\", wkhtmltopdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b68bd97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sri lakshmi prasanna\\anaconda3\\envs\\llmsenv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db4213c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_markdown(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79e6d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abfb8f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here it is - see the base_url\n",
    "# You need to do this one time on your computer\n",
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73f702f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's lovely to meet you! I'm thrilled to be your first conversational partner. How are you doing today? Is there something specific you'd like to chat about or ask for help with? I'm all ears (or rather, all text) and here to assist you!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"Hello, Llama! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe35efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Translate using local LLaMA 3\n",
    "def translate_to_spanish(content):\n",
    "    prompt = f\"Translate the following Markdown brochure to Spanish while keeping all formatting (like #, **, etc.) intact:\\n\\n{content}\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.4\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38acfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Save translated output\n",
    "def save_translation(content, output_path=\"brochure_es.md\"):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "    print(f\"✅ Translated brochure saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4dc29afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Translated brochure saved to brochure_es.md\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Run the process\n",
    "if __name__ == \"__main__\":\n",
    "    brochure = read_markdown(\"brochure.md\")\n",
    "    translated = translate_to_spanish(brochure)\n",
    "    save_translation(translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def zip_exports():\n",
    "    shutil.make_archive(\"huggingface_brochure\", \"zip\", \".\", \".\", verbose=1)\n",
    "    \n",
    "# Call the function to create the zip\n",
    "zip_exports()  \n",
    "# all packages export function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
